# RAG Learning Tasks Assistant

Идея: построить учебную систему с Retrieval Augmented Generation, которая подсказывает и объясняет задания курса. Для каждого запроса студента система тянет релевантный контент из векторного хранилища, дополняет его структурированными данными из других БД и формирует ответ через LLM.

## Используемые хранилища и их роли

- **PostgreSQL** – основная транзакционная база: хранит пользователей, задания курса, дедлайны, статусы сдачи, ссылки на источники. Здесь удобно вести нормализованные таблицы и использовать сложные запросы/представления для отчётности.
- **MongoDB** – документное хранилище для неструктурированного контента: методички, заметки преподавателя, истории чатов студентов с ассистентом. Каждый документ снабжается метаданными, которые потом уходят в пайплайн векторизации.
- **Redis** – in-memory слой для кешей и быстрого state management. Кешируем ответы LLM, популярные embedding-запросы, авторизационные токены, а также используем Redis Streams для событийной шины (например, когда загружен новый набор материалов).
- **Qdrant** – векторная БД, куда попадают эмбеддинги заданий, решений, объяснений и сообщений студентов. Основной retrieval проходит через Qdrant (HNSW), а результаты обогащаются из Postgres/Mongo перед тем, как уйти в LLM.
- **Neo4j** (опционально) – граф знаний курса: вершины – концепции и задания, рёбра – зависимости («понять B можно после A»). В RAG-маршруте можно делать дополнительный hop: зная, что студент спрашивает про тему X, вытягиваем соседей через Cypher и добавляем контекст в промпт. Также граф полезен для построения персональных дорожных карт.

## Архитектура (высокоуровневый набросок)

1. **ETL/ingestion**: преподаватель загружает материалы → сервис кладёт «сырые» документы в MongoDB, добавляет метаданные в Postgres, формирует события в Redis Streams.
2. **Embedding pipeline**: воркер слушает стрим, забирает документы, создаёт эмбеддинги (векторизация текста и кода), складывает их в Qdrant и записывает ссылку на вектор в Postgres.
3. **Graph builder**: отдельный сервис анализирует задания и строит граф зависимостей, записывая вершины и рёбра в Neo4j.
4. **RAG API**:
   - принимает запрос студента;
   - смотрит профиль пользователя и историю попыток в Postgres;
   - при необходимости достаёт свежие заметки из Mongo;
   - обращается в Qdrant за k ближайшими векторами;
   - по ID документов тянет структуру из Postgres/Mongo;
   - расширяет контекст через Neo4j (по теме или соседним концепциям);
   - собирает промпт, прогоняет через LLM, результат кеширует в Redis.

## Черновой план работ

1. **Скейfoldинг**: описать docker-compose с сервисами (Postgres, Mongo, Redis, Qdrant, Neo4j, API, воркер).
2. **Схемы данных**:
   - Postgres: `users`, `assignments`, `submissions`, `documents`, `vector_refs`.
   - Mongo: `materials`, `chat_logs`, `notes`.
   - Redis: namespaces `cache:*`, `session:*`, `stream:ingest`.
   - Qdrant: коллекции `assignments_vectors`, `notes_vectors`.
   - Neo4j: метки `Concept`, `Assignment`; типы рёбер `REQUIRES`, `RELATES_TO`.
3. **Первый пайплайн**: загрузка учебного задания → запись в Mongo → событие в Redis → воркер создаёт embedding и пишет в Qdrant + Postgres.
4. **MVP RAG endpoint**: REST/GraphQL метод `POST /rag/query` с параметрами `user_id`, `query`. Возвращает ответ LLM + ссылки на использованные источники.
5. **Дополнительно**: интерфейс для преподавателя (веб или телеграм-бот) с формами загрузки материалов и глазами на граф Neo4j.

## Что можно набросать уже сейчас

- Описать .proto/.json схемы событий в Redis Streams.
- Прописать миграции Postgres и дефолтные индексы.
- Подготовить моковые данные в Mongo и прогнать через черновой embedding-воркер (можно использовать заглушку без обращения к настоящему LLM).
- Настроить базовые коллекции в Qdrant (HTTP API) и проверить поиск по нескольким документам.
- Поднять Neo4j и набить демо-граф из пары десятков концепций, чтобы тестировать Cypher-запросы.

Такой проект показывает, как разные базы данных дополняют друг друга: строгие транзакции и репорты в Postgres, гибкий документный слой в MongoDB, быстрый state в Redis, контекстный поиск в Qdrant и семантические связи в Neo4j.

## Быстрый старт: рабочая векторная БД

1. **Запусти инфраструктуру**  
   ```bash
   docker compose up -d
   ```
   Это поднимет PostgreSQL, MongoDB, Redis, Qdrant и Neo4j с готовыми томами. Postgres инициализируется схемой `infra/postgres/init.sql`.

2. **Установи зависимости** (локальный Python 3.10+):  
   ```bash
   python -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   ```

3. **Загрузи материалы и векторы**  
   Отредактируй `data/materials.json`, затем выполни:
   ```bash
   python scripts/ingest.py
   ```
   Скрипт создаст задания в PostgreSQL, документы в MongoDB, эмбеддинги (детерминированная заглушка) и точки в Qdrant, а также события в Redis Streams.

4. **Проверь поиск**  
   ```bash
   python scripts/search.py "пайплайн RAG"
   ```
   CLI извлечёт ближайшие векторы из Qdrant и покажет связанный текст из PostgreSQL (название задания, источник, содержимое чанка).

### Переменные окружения

Все скрипты читают стандартные DSN и хосты, их можно переопределить:

| Переменная | Значение по умолчанию |
|------------|-----------------------|
| `POSTGRES_DSN` | `postgresql://rag:ragpass@localhost:5432/rag` |
| `MONGODB_URI` | `mongodb://localhost:27017` |
| `REDIS_URL` | `redis://localhost:6379/0` |
| `QDRANT_HOST` / `QDRANT_PORT` | `localhost` / `6333` |
| `QDRANT_COLLECTION` | `course_materials` |
| `EMBEDDING_DIM` | `384` |
| `INGEST_STREAM` | `stream:ingest` |

Такой сетап уже работает: после `docker compose up` можно загружать демо-данные и выполнять поиск поверх локальной Qdrant, имея при этом полную связку Postgres + Mongo + Redis + Neo4j для дальнейшего развития RAG-системы.
