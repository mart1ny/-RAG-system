[
  {
    "title": "Стартовый модуль: Понимаем, что такое RAG",
    "topic": "rag-intro",
    "description": "Зачем образовательному ассистенту Retrieval Augmented Generation и как компоненты работают вместе.",
    "source": "module_intro.md",
    "chunks": [
      "Retrieval Augmented Generation (RAG) объединяет генеративную модель с поисковым слоем, который подставляет в промпт свежие факты — поэтому ответы звучат личностно, но при этом остаются точными.",
      "Команда Facebook Research описывает RAG как конвейер: encode → retrieve → generate; важно, что retrieval использует отдельную базу знаний и может обновляться независимо от обучения LLM.",
      "Для старта курса полезно прочитать README репозитория https://github.com/facebookresearch/RAG и обратить внимание на разделы про обучение retriever’а и генератора.",
      "Задача преподавателя — объяснить студентам, что RAG не отменяет традиционную базу знаний, а превращает её в контекст, который LLM использует перед ответом.",
      "В образовательной среде RAG помогает: 1) объяснять новые темы, 2) ссылаться на методички, 3) подбирать соседние концепции через граф знаний.",
      "Студенты быстрее усваивают идею RAG, если показать короткий пример: запрос → подбор чанков → генерация с цитированием. Используйте demo-скрипт из проекта.",
      "При первом занятии стоит обсудить ограничения: модель «знает» ровно то, что успели залить в базу, и каждое обновление требует перезапуска ingestion.",
      "Домашнее задание: найти не менее трёх реальных кейсов применения RAG и подготовить мини-презентацию с анализом плюсов/минусов."
    ],
    "notes": [
      "Попросите студентов вести «дневник понимания» — что было ясно, а что нет после ознакомления с материалами.",
      "Обсудите термины retrieval, rerank, prompt enrichment, чтобы у всех была общая терминология."
    ]
  },
  {
    "title": "Этапы пайплайна: от документов до векторной базы",
    "topic": "rag-pipeline",
    "description": "Детально разбираем ingestion: как подготовить данные, генерировать эмбеддинги, валидировать и мониторить загрузку.",
    "source": "module_pipeline.md",
    "chunks": [
      "Пайплайн начинается с инвентаризации источников: Markdown, конспекты, PDF, базы вопросов; для каждого определяем формат хранения и периодичность обновления.",
      "Чанкинг должен учитывать педагогический контекст: логично резать по смысловым блокам (параграф, пример, шаг решения), а не по фиксированным 512 токенам.",
      "Эмбеддинги можно генерировать локально (sentence-transformers/all-MiniLM-L6-v2) или через облачные сервисы; важно хранить в Qdrant не только вектора, но и payload с темой и источником.",
      "Postgres используется как источник правды о заданиях: таблицы assignments, documents, vector_refs — они позволяют связать текст с вектором и студентом.",
      "MongoDB хранит оригинальные материалы, чтобы можно было быстро пересобрать чанки или построить новый тип инференса (например, RAG + суммаризация).",
      "Redis Streams нужен для событий ingestion: если преподаватель загрузил новую методичку, worker получает событие и перестраивает эмбеддинги.",
      "Ключевой процесс контроля качества — валидация пайплайна: проверяем, что для каждого документа есть вектор, документ не пустой, есть ссылка на тему курса.",
      "Совет студентам: собирайте отчёт после каждой загрузки — сколько документов обработано, сколько пропущено, какие ошибки в логах."
    ],
    "notes": [
      "Покажите Flowchart с этапами ingestion, чтобы визуально закрепить процесс.",
      "Дайте практику: написать скрипт, который проверяет консистентность количества документов между Postgres и Qdrant."
    ]
  },
  {
    "title": "Граф знаний Neo4j и персональные подсказки",
    "topic": "rag-graph",
    "description": "Neo4j помогает связывать концепции курса, предлагать соседние темы и делать визуальные подсказки в UI.",
    "source": "module_graph.md",
    "chunks": [
      "В графе есть два типа вершин: Concept (темы) и Assignment (задания). Рёбра RELATES_TO показывают соседей по теме, ASSOCIATED_WITH — какие задания раскрывают концепцию.",
      "При ingestion мы добавляем вершины и связи: MERGE (a:Assignment {id}), MERGE (c:Concept {topic}), MERGE (a)-[:ASSOCIATED_WITH]->(c).",
      "На запросе API делает Cypher MATCH (c:Concept) WHERE c.id IN topics, подтягивает соседей и возвращает мини-граф, который визуализируется во фронте.",
      "В Neo4j можно проверять полноту курсного графа: есть ли темы без заданий, нет ли изолированных узлов, правильно ли проставлены prerequirements.",
      "Graph hop полезен для персонализации — например, если студент спрашивает про трансформеры, UI показывает соседей: attention, positional encoding, BPE.",
      "Для сложных курсов можно построить несколько слоёв графа: концепции, навыки, оценочные мероприятия. Cypher выдерживает такие запросы.",
      "Рекомендуйте студентам Graph Academy (https://graphacademy.neo4j.com) и официальные примеры Cypher, чтобы они уверенно писали запросы.",
      "Визуализация в UI — не только красивая фича: она помогает студенту увидеть, куда двигаться по теме и какие задания повторить."
    ],
    "notes": [
      "Дайте мини-лабораторную: заполнить Neo4j данными по одной теме и построить граф запросами MATCH/CREATE.",
      "Совет: храните версию графа (timestamp), чтобы отслеживать изменения при обновлении курса."
    ]
  },
  {
    "title": "Качество и оценка RAG-системы",
    "topic": "rag-evaluation",
    "description": "Обсуждаем метрики, сбор обратной связи, чек-листы, ручные и автоматические тесты, чтобы RAG-ассистент не деградировал.",
    "source": "module_eval.md",
    "chunks": [
      "Авторы статьи https://arxiv.org/abs/2106.10635 предлагают измерять hit-rate retrieval’а, точность фактов и согласованность генерации — адаптируйте это под учебный сценарий.",
      "Соберите набор сложных вопросов (tricky cases) и прогоняйте через ассистента после каждого обновления данных. Сравнивайте ответы с эталонными.",
      "UI должен иметь кнопку обратной связи «помогло / не помогло» и возможность студенту оставить комментарий. Эти данные важно агрегировать.",
      "Отдельно фиксируйте вопросы без найденных материалов — это индикатор, что нужно расширить базу или построить новые связи.",
      "Проводите ежемесячный аудит графа: если тема не связана ни с одним заданием, значит, пайплайн ingestion что-то пропустил.",
      "Мониторинг: выводите в Grafana долю успешных ответов, латентность запроса, количество обращений к Neo4j. Это помогает ловить деградации.",
      "Основная рекомендация студентам — не бояться ручной проверки: только человек заметит, насколько ответ действительно полезен одногруппнику.",
      "Для курсов с несколькими преподавателями заведите общий чек-лист качества: актуальность материалов, полнота графа, корректные ссылки в ответах."
    ],
    "notes": [
      "Практика: построить таблицу метрик и заполнить её по результатам последнего релиза ассистента.",
      "Попросите студентов разработать план A/B-теста, чтобы сравнить разные версии промптов или источников."
    ]
  },
  {
    "title": "Интеграция данных: PDF, презентации, API",
    "topic": "rag-data-ingestion",
    "description": "Превращаем разрозненные источники в единый корпус: извлекаем текст из PDF/Slides, получаем данные через API и готовим их к ingestion.",
    "source": "module_data.md",
    "chunks": [
      "PDF часто содержат сложное форматирование. Используйте сочетание pdfminer + heuristic: табличные элементы переносите в Markdown таблицы, подписи к рисункам — отдельными чанками.",
      "Презентации PPTX стоит конвертировать в Markdown с сохранением структуры: заголовок слайда → заголовок чанка, bullet → список. Это помогает LLM понимать порядок.",
      "API (например, GitHub или LMS) можно подключить через ETL-сервис: забираем новые issues/обсуждения и конвертируем в текстовые заметки.",
      "При работе с кодом полезно хранить фрагменты отдельно и добавлять язык программирования в payload, чтобы ассистент мог фильтровать по технологиям.",
      "Обязательно добавляйте метаданные: автор материала, дата обновления, тема курса, тип источника (методичка, практика, проект). Это помогает для аналитики и фильтрации.",
      "Рекомендуемая структура каталога: data/raw для оригиналов, data/processed для очищенных файлов, data/materials.json для итоговой подборки.",
      "Настройте проверку линков (link checker), чтобы при генерации ответов ассистент не ссылался на устаревшие URL.",
      "Учебный лайфхак: попросите студентов оформить собственную заметку в формате, совместимом с ingestion, чтобы они прочувствовали pipeline."
    ],
    "notes": [
      "Дайте ссылку на примеры конвертации PDF→Markdown (например, проект nougat) и попросите студентов протестировать.",
      "Обсудите правовые аспекты: можно ли загружать материалы с платных платформ, требуется ли разрешение авторов."
    ]
  },
  {
    "title": "Локальные модели: эмбеддинги и генерация",
    "topic": "rag-local-llm",
    "description": "Как запускать sentence-transformers и llama.cpp локально, что нужно для производительности и как это влияет на ответы.",
    "source": "module_llm.md",
    "chunks": [
      "Для эмбеддингов используем sentence-transformers/all-MiniLM-L6-v2 — 384-мерная модель, хорошо подходит для ноутбуков. Убедитесь, что версия torch совместима с вашей архитектурой.",
      "llama-cpp-python позволяет подгружать GGUF модели (например, Phi-3 mini) прямо в Python-приложение. Настройте LLAMA_THREADS и LLAMA_GPU_LAYERS под возможности ноутбука.",
      "В ответах API добавляет few-shot примеры и граф контекста, чтобы локальная модель генерировала структурированные пункты и упоминала источники.",
      "Если модель не загрузилась, ассистент автоматически откатывается на Markdown-фоллбек — это позволяет не прерывать работу курса.",
      "Храните GGUF файлы в каталоге models/ и добавьте его в .gitignore, чтобы не заливать гигабайты в репозиторий.",
      "При тестировании узнавайте фактическую латентность: сколько времени занимает один запрос? Можно выводить метрики в консоль или Grafana.",
      "Следите за обновлениями моделей: некоторые GGUF версии включают оптимизации для Apple Silicon, что сокращает время генерации почти вдвое.",
      "Домашнее задание: запустить локальную модель с другим контекстом (например, 8192 токенов) и измерить влияние на скорость и качество."
    ],
    "notes": [
      "Рекомендуйте студентам раздел llama.cpp Performance Tips (https://github.com/ggerganov/llama.cpp/wiki/Performance-Tips).",
      "Напомните, что локальная модель требует памяти: 4-битная Phi-3 занимает ~2.2 ГБ. Планируйте ресурсы заранее."
    ]
  },
  {
    "title": "Рекомендательный слой и персонализация",
    "topic": "rag-recommendations",
    "description": "Используем историю студента, граф Neo4j и дополнительные фильтры, чтобы давать осмысленные подсказки и следующий шаг обучения.",
    "source": "module_reco.md",
    "chunks": [
      "История запросов студента хранится в MongoDB: вы можете учитывать последние темы, не повторять рекомендованные задания и подсказывать пробелы.",
      "Neo4j помогает вычислить ближайшие темы: MATCH (c:Concept {id:$topic})-[:RELATES_TO]->(n) — это мгновенная рекомендация «что изучить дальше».",
      "Можно строить персональные чек-листы: если студент провалил задание, связываем его тему с зависимыми концепциями и предлагаем повторить.",
      "RAG-ответы стоит дополнять блоком «Попробуй ещё»: перечислить соседние задания, полезные статьи, короткие шпаргалки.",
      "Для рефлексии добавьте кнопку «помогло/нет» — эти данные записываются в Redis или Postgres и влияют на будущие рекомендации.",
      "Не забывайте про ограничения: персонализация не должна подменять преподавательский контроль и выходить за рамки программы.",
      "В UI можно визуализировать мини-граф (как у нас) или простую таймлайн-карточку: изучено/в процессе/ожидает повторения."
    ],
    "notes": [
      "Совет лекторам: не усложняйте рекомендации, пока не выстроен базовый RAG-поток. Сначала убедитесь, что retrieval работает стабильно.",
      "Назначьте ответственным группу студентов, чтобы они тестировали рекомендательные подсказки и сообщали о неточностях."
    ]
  },
  {
    "title": "Инфраструктура и мониторинг",
    "topic": "rag-infra",
    "description": "Как организовать запуск контейнеров, мониторинг сервисов, backup данных и CI/CD для образовательного ассистента.",
    "source": "module_infra.md",
    "chunks": [
      "Docker Compose поднимает Postgres, MongoDB, Redis, Qdrant и Neo4j. Для production лучше разделить эти компоненты по отдельным инстансам.",
      "Postgres и Qdrant обязательно бекапьте: используйте cron + pg_dump, snapshot Qdrant storage и храните артефакты в защищённом bucket.",
      "Prometheus + Grafana помогут отслеживать latency запросов, доступность сервисов и количество обращений к Neo4j.",
      "CI/CD: после каждого merge запускайте тесты ingestion (минимальный набор документов), проверку схемы Postgres и миграций Neo4j.",
      "Рассмотрите возможность развернуть ассистента в Kubernetes: это упростит масштабирование жанадежность.",
      "Не забывайте про безопасность: ограничьте доступ к Neo4j и Postgres, используйте .env только локально и не коммитьте его в git.",
      "В README держите актуальный гайд по запуску, чтобы новый преподаватель или студент смог поднять стек за вечер.",
      "Совет: раз в семестр делайте «fire drill» — симулируйте падение одного из сервисов и проверяйте, как быстро сможете восстановить работу."
    ],
    "notes": [
      "Попросите студентов сделать обзор мониторинговых инструментов и предложить дешёвые альтернативы Grafana/Prometheus.",
      "Добавьте в план занятия практику — посмотреть логи сервисов через docker compose logs -f и найти источник ошибки."
    ]
  },
  {
    "title": "Сценарии использования и best practices",
    "topic": "rag-use-cases",
    "description": "Собираем реальные сценарии: помощь в лабораторных, объяснение задач, подготовка к экзаменам, поддержка преподавателя.",
    "source": "module_usecases.md",
    "chunks": [
      "Лабораторные: студент задаёт вопрос про конкретную функцию, ассистент находит соответствующие конспекты и объясняет пошагово, ссылаясь на материалы.",
      "Подготовка к экзамену: ассистент формирует чек-лист тем, показывает соседние концепции в графе и предлагает задания для повторения.",
      "Поддержка преподавателя: можно быстро посмотреть, какие темы чаще всего вызывают вопросы, и оперативно обновить граф или материалы.",
      "Совместная работа: ассистент помогает в форумах курса — отвечая на часто задаваемые вопросы, он ссылается на официальные методички.",
      "Психологический аспект: когда ответ снабжён ссылками и графом, студенту легче доверять ассистенту и понимать, что это не «чёрный ящик».",
      "В blended-learning сценариях RAG помогает студентам во время офлайн-занятий: можно запросить краткую шпаргалку по текущей теме.",
      "Для начинающих преподавателей ассистент служит «вики» курса — быстро напоминает связки тем и даёт ссылки на актуальные задания.",
      "Экспериментальная идея: интегрировать ассистент с LMS, чтобы автоматически подсказывать ресурсы, когда студент сдаёт задание позже дедлайна."
    ],
    "notes": [
      "Составьте вместе со студентами таблицу «Сценарий → какой контент нужен → кто отвечает за актуальность», чтобы распределить ответственность.",
      "Поощряйте делиться фидбеком: лучшие кейсы можно включать в презентации курса или использовать как демонстрации для новых групп."
    ]
  },
  
  { "title": "ML: Основы линейной алгебры для обучения", "topic": "ml-linear-algebra", "description": "Понимание матриц и векторов — фундамент большинства алгоритмов машинного обучения.", "source": "ml_module_linalg.md", "chunks": ["Линейная комбинация векторов позволяет описывать пространство гипотез и понимать, как модели комбинируют признаки.", "Матрица признаков X и вектор целей y используются в большинстве оптимизационных задач; важно знать операции умножения, транспонирования, вычисления определителя.", "Собственные значения и собственные векторы применяются в PCA и других методах уменьшения размерности."], "notes": ["Порекомендуйте студентам «Linear Algebra Done Right» и визуализации 3Blue1Brown.", "Домашнее задание: реализовать умножение матриц и проверить результат на PyTorch/NumPy."] },
  { "title": "ML: Градиентный спуск", "topic": "ml-gradient-descent", "description": "Как устроен градиентный спуск и его вариации для оптимизации функций потерь.", "source": "ml_module_gradients.md", "chunks": ["Классический градиентный спуск обновляет веса w = w - eta * grad(L); выберите шаг eta так, чтобы избежать расходимости.", "Стохастический и мини-батч градиентный спуск ускоряют обучение на больших датасетах, но вносят шум в оценку градиента.", "Адаптивные оптимизаторы (Adam, RMSProp) подстраивают скорость обучения для каждого признака."], "notes": ["Предложите студентам визуализировать траекторию спуска на простой функции (например, параболе).", "Попросите реализовать мини-батч версию и сравнить с full-batch по числу итераций."] },
  { "title": "ML: Регуляризация", "topic": "ml-regularization", "description": "Методы борьбы с переобучением: L1, L2, dropout, ранняя остановка.", "source": "ml_module_regularization.md", "chunks": ["L1-регуляризация добавляет член |w| и способствует разреженности весов, L2 (||w||^2) сглаживает большие веса.", "Dropout отключает случайные нейроны во время обучения, что заставляет сеть учиться более устойчивым признакам.", "Ранняя остановка (early stopping) следит за метрикой на валидации и прекращает обучение, когда качество перестаёт улучшаться."], "notes": ["Дайте практику: реализовать L2-регуляризацию в линейной регрессии.", "Обсудите компромисс: сильная регуляризация может привести к недообучению."] },
  { "title": "ML: Кросс-валидация и выбор модели", "topic": "ml-cross-validation", "description": "Как корректно оценивать качество модели и выбирать гиперпараметры.", "source": "ml_module_cv.md", "chunks": ["K-fold кросс-валидация разбивает датасет на K блоков и обучает модель K раз, каждый раз используя один блок как валидацию.", "Stratified k-fold важен для несбалансированных классов — он сохраняет пропорции классов в каждой выборке.", "Nested cross-validation полезен при подборе гиперпараметров, чтобы избежать потока информации из теста в обучение."], "notes": ["Порекомендуйте scikit-learn документацию по KFold/StratifiedKFold.", "Домашнее задание: реализовать простой grid search с кросс-валидацией."] },
  { "title": "ML: Обработка текстов", "topic": "ml-nlp-basics", "description": "Bag-of-words, TF-IDF, нейронные эмбеддинги.", "source": "ml_module_nlp.md", "chunks": ["Bag-of-words считает частоту слов и игнорирует порядок; TF-IDF поднимает редкие, но важные слова.", "Word2Vec/GloVe обучают векторы слов на основе контекста и позволяют измерять семантическую близость.", "Современные подходы (BERT, transformers) учитывают контекст и позицию слова в предложении."], "notes": ["Задайте практику: построить TF-IDF матрицу и обучить логистическую регрессию для классификации отзывов.", "Продвинутым студентам предложите реализовать простое fine-tuning BERT на HuggingFace."] },
  { "title": "ML: Глубокое обучение — основы", "topic": "ml-deep-learning", "description": "Структура нейронных сетей, функции активации, обратное распространение ошибки.", "source": "ml_module_dl.md", "chunks": ["Многослойный перцептрон (MLP) состоит из чередующихся линейных слоёв и нелинейных активаторов (ReLU, sigmoid, tanh).",
      "Обратное распространение ошибки вычисляет градиент функции потерь по параметрам сети, используя цепное правило.",
      "Batch Normalization стабилизирует распределение активаций и ускоряет обучение."],
    "notes": ["Порекомендуйте курс deeplearning.ai и главу о backpropagation из книги Michael Nielsen.", "Практика: реализовать forward/backward pass для двухслойной сети в NumPy."] },
  { "title": "ML: CNN для компьютерного зрения", "topic": "ml-cnn",
    "description": "Свёрточные нейронные сети и их применение к задачам распознавания изображений.",
    "source": "ml_module_cnn.md",
    "chunks": ["Свёртки извлекают локальные признаки, pooling уменьшает размерность, fully-connected слои завершают классификацию.", "Архитектуры VGG, ResNet, EfficientNet демонстрируют разные подходы к глубине и остаточным связям.", "Data augmentation (повороты, отражения, шум) повышает устойчивость модели к разнообразию данных."],
    "notes": ["Дайте студентам задачу: натренировать простую CNN на MNIST/CIFAR и сравнить с базовой MLP.", "Обсудите вопрос переобучения и способы борьбы с ним (dropout, regularization)."] },
  { "title": "ML: RNN и обработка последовательностей", "topic": "ml-rnn",
    "description": "Рекуррентные сети, LSTM, GRU, их ограничения и применение.",
    "source": "ml_module_rnn.md",
    "chunks": ["RNN передают состояние из шага в шаг, но страдают от затухающего градиента.", "LSTM вводит ячейку памяти и три гейта, что помогает сохранять контекст на длинных последовательностях.", "GRU упрощает архитектуру и быстрее обучается при сопоставимом качестве."],
    "notes": ["Покажите студентам визуализации LSTM из colah.github.io.", "Практика: обучить LSTM/GRU для генерации текста или предсказания временных рядов."] },
  { "title": "ML: Transformer и внимание", "topic": "ml-transformer",
    "description": "Механизм self-attention, encoder-decoder архитектуры, BERT/ GPT.",
    "source": "ml_module_transformer.md",
    "chunks": ["Self-attention вычисляет вес связи между каждой парой токенов, позволяя модели учитывать глобальные зависимости.", "Encoder-decoder трансформеры (как оригинальный Transformer) подходят для seq2seq задач (перевод, суммаризация).", "BERT обучается на masked language modeling и next sentence prediction для получения универсальных представлений."],
    "notes": ["Порекомендуйте студентам оригинальную статью «Attention Is All You Need».",
      "Домашнее задание: использовать HuggingFace Transformers для fine-tune простого классификатора."] },
  { "title": "ML: Обработка табличных данных", "topic": "ml-tabular",
    "description": "Сравниваем алгоритмы для табличных данных: градиентный бустинг, случайный лес, CatBoost.",
    "source": "ml_module_tabular.md",
    "chunks": ["Градиентный бустинг строит ансамбль слабых моделей (деревьев), последовательно исправляющих ошибки предыдущих.", "CatBoost работает с категориальными признаками без явного one-hot кодирования, что удобно для бизнес-данных.", "Stacking/Blending позволяют комбинировать разные модели и повышать качество на табличных задачах."],
    "notes": ["Предложите студентам Kaggle-подобный проект: предсказать churn клиентов с использованием CatBoost.", "Обсудите вопрос интерпретируемости: SHAP, feature importance, PDP."] },
  { "title": "ML: Модели временных рядов", "topic": "ml-time-series",
    "description": "ARIMA, Prophet, LSTM для прогнозирования временных рядов.",
    "source": "ml_module_timeseries.md",
    "chunks": ["ARIMA строит линейные модели с учётом авторегрессии и скользящего среднего; требуется стационарность ряда.", "Facebook Prophet автоматизирует работу с трендами и сезонностями, подходит для бизнес-forecasting.", "Временные ряды можно прогнозировать нейросетями (Temporal CNN, LSTM, Transformer). Важно учитывать масштаб и сезонность."],
    "notes": ["Домашняя работа: спрогнозировать продажи продуктов на основе исторических данных, сравнив ARIMA и Prophet.", "Порекомендуйте читать блог Rob J Hyndman о временных рядах."] },
  { "title": "ML: Несбалансированные выборки", "topic": "ml-imbalance",
    "description": "SMOTE, взвешивание классов, метрики для несбалансированных данных.",
    "source": "ml_module_imbalance.md",
    "chunks": ["Accuracy не подходит при сильном дисбалансе; используйте precision/recall, F1-score, ROC-AUC, PR-AUC.", "SMOTE синтезирует новые примеры миноритарного класса, но важно избегать выхода за границы реальных данных.", "Взвешенные функции потерь и class_weight помогают уделить больше внимания редким событиям."],
    "notes": ["Практика: взять датасет fraud detection и сравнить baseline accuracy с F1-score.", "Объясните, почему oversampling/undersampling нужно применять только в обучении, чтобы не искажать тестовую выборку."] },
  { "title": "ML: Интерпретируемость моделей", "topic": "ml-interpretability",
    "description": "LIME, SHAP, partial dependence plots, feature importance.",
    "source": "ml_module_interpret.md",
    "chunks": ["LIME обучает локальную интерпретируемую модель вокруг конкретного предсказания и показывает наиболее влияющие признаки.", "SHAP основан на теории игровых значений и вычисляет вклад каждого признака в предсказание.", "Partial dependence plot показывает среднее влияние признака на предсказание при фиксировании других переменных."],
    "notes": ["Дайте студентам задание: объяснить предсказание модели мошенничества с помощью SHAP.", "Порекомендуйте использовать интерпретируемость для проверок fairness и bias."] },
  { "title": "ML: AutoML и поиск гиперпараметров", "topic": "ml-automl",
    "description": "AutoML-платформы, Bayesian Optimization, Hyperband.",
    "source": "ml_module_automl.md",
    "chunks": ["Auto-sklearn, TPOT, H2O AutoML автоматизируют выбор моделей и гиперпараметров."],
    "notes": ["Сравните ручной подбор гиперпараметров и использование AutoML на одном датасете." ] }
]
